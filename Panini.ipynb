{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python modules\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import threading\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "#Plotting Tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "#NLTK\n",
    "import nltk\n",
    "\n",
    "#Scikit learn models \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Chemdataextractor\n",
    "from chemdataextractor.doc import Document, Heading, Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDF=pd.read_csv('Final_Abstracts_lda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDF=MDF[['PII','Title_x','Abstract_x']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(DF, column_name):\n",
    "    data = d[column_name].tolist()\n",
    "    data_words = list(sent_to_words(data))\n",
    "    \n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100) \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    data_words_nostops = [[word for word in simple_preprocess(str(doc)) if word not in STOPWORDS] for doc in data_words]\n",
    "    data_words_bigrams = [bigram_mod[doc] for doc in data_words_nostops]\n",
    "    \n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "    texts = data_words_bigrams\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "    return corpus, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "             yield(simple_preprocess(str(sentence), deacc=True)) \n",
    "        \n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    text=\" \".join(text.split())\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in STOPWORDS and len(token) > 3:\n",
    "            result.append((token))\n",
    "    return result\n",
    "\n",
    "def sim_calculator(DF, column_name):\n",
    "\n",
    "    print(\"Number of {}: {}\".format(column_name,len(DF[column_name])))\n",
    "\n",
    "    #Preprocessing\n",
    "    print('\\nCreating Dictionary...')\n",
    "    processed_docs = DF[column_name].map(preprocess)\n",
    "\n",
    "    #Generating dictionary\n",
    "    dictionary = corpora.Dictionary(processed_docs)\n",
    "    dictionary.filter_extremes(no_below=100,no_above=0.9, keep_n=100000)\n",
    "    print('Dictionary created')\n",
    "    print(\"Size of vocabularly: \",len(dictionary))\n",
    "\n",
    "    #Bag of words\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "    #Tfid vectorization\n",
    "    print('\\nRunning TFIDF vectorization...')\n",
    "    model2 = TfidfModel(bow_corpus) \n",
    "    abs_tfidf=model2[bow_corpus]\n",
    "    print('TFIDF complete')\n",
    "\n",
    "    #Calculating similarties\n",
    "    print('\\nCalculating Similarity Matrix...')\n",
    "    index = similarities.MatrixSimilarity(abs_tfidf)\n",
    "    sims = index[abs_tfidf]\n",
    "    print(\"size of similarity matrix: \", sims.shape)\n",
    "\n",
    "    return sims\n",
    "\n",
    "def tsne(sims,title,DF,i):\n",
    "\n",
    "    #run PCA\n",
    "    print(\"\\nBeginning clustering...\")\n",
    "    N=100\n",
    "    pca = PCA(n_components=N)\n",
    "    pca_result = pca.fit_transform(sims)\n",
    "    var=np.sum(pca.explained_variance_ratio_)\n",
    "    print(\"\\nPCA calculated\")\n",
    "    print('Cumulative explained variation for {} principal components: {}'.format(N,var))\n",
    "\n",
    "    #Running TSNE\n",
    "    print(\"Creating TSNE labels...\")\n",
    "    tsne=TSNE(n_components=2,verbose=1,perplexity=40,n_iter=300)\n",
    "    tsne_results=tsne.fit_transform(pca_result)\n",
    "    print(\"TSNE complete\")\n",
    "    DF['x-label-'+str(i)]=tsne_results[:,0]\n",
    "    DF['y-label-'+str(i)]=tsne_results[:,1]\n",
    "\n",
    "    return str(np.round(var*100,2))\n",
    "\n",
    "def dictionarizer(DF,topic_num):\n",
    "    \n",
    "    topic_num=str(topic_num)\n",
    "    size_dict={}\n",
    "    tag_list=list(set(DF[topic_num+'-topic']))\n",
    "\n",
    "    for tag in tag_list:\n",
    "        val=len(DF[DF[topic_num+'-topic']==tag])\n",
    "        size_dict[str(tag)]=val\n",
    "\n",
    "    for tag in tag_list:\n",
    "        size_dict[str(tag)]=np.around(size_dict[str(tag)]*20/max(list(size_dict.values()))+7,2)\n",
    "\n",
    "    sorted_dict={}\n",
    "    for w in sorted(size_dict, key=size_dict.get):\n",
    "        sorted_dict[w]=size_dict[w]\n",
    "\n",
    "    return sorted_dict\n",
    "\n",
    "def scatter(DF,sorted_dict,topic_num,i,title,session_id,var='62.3'):\n",
    "    \n",
    "    sample_size=len(DF)\n",
    "    \n",
    "    topic_num=str(topic_num)\n",
    "    print(\"\\nCreating LDA plot...\")\n",
    "\n",
    "    if len(DF)>=50000:\n",
    "        s=10\n",
    "    else:\n",
    "        s=40\n",
    "\n",
    "    palette = np.array(sns.color_palette(\"hls\", len(sorted_dict)+5))\n",
    "\n",
    "    f = plt.figure(figsize=(12, 12))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(DF['x-label-'+str(i)], DF['y-label-'+str(i)], s,lw=0,c=palette[DF[topic_num+'-topic'].astype(np.int)])\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    txts = []\n",
    "    for item in sorted_dict.keys():\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(DF[DF[topic_num+'-topic']==float(item)][['x-label-'+str(i),'y-label-'+str(i)]],axis=0)\n",
    "        if not math.isnan(xtext) and not math.isnan(ytext):\n",
    "            txt = ax.text(xtext, ytext, item, fontsize=sorted_dict[item])\n",
    "            txt.set_path_effects([\n",
    "                PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "                PathEffects.Normal()])\n",
    "            txts.append(txt)\n",
    "\n",
    "    PCA_text='PCA: 100 \\nTotal Variance: '+var\n",
    "\n",
    "    plt.title('Cluster plot of '+str(sample_size)+' Abstracts with '+topic_num+' topics')\n",
    "    plt.annotate(PCA_text, xy=(0,0), xytext=(12, 80), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "    plt.savefig(title+'_'+session_id+'.png')\n",
    "    print(\"\\nLDA plot saved as {} at {}\".format(title+'.png',os.getcwd()))\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \n",
    "    def __init__(self,address):\n",
    "        \n",
    "        self.session_id=self.randomString()\n",
    "        \n",
    "        if type(address)==str:\n",
    "            self.DF=pd.read_csv(address)\n",
    "        elif isinstance(NDF, pd.DataFrame):\n",
    "            self.DF=address\n",
    "        \n",
    "        self.size=len(self.DF)\n",
    "        \n",
    "        self.lda_model=[]\n",
    "        \n",
    "        \n",
    "    def randomString(self,stringLength=8):\n",
    "        lettersAndDigits = string.ascii_letters + string.digits\n",
    "        return ''.join(random.choice(lettersAndDigits) for i in range(stringLength))\n",
    "    \n",
    "    def run_LDA(self,column_name, topic_num, passes=10):\n",
    "        \n",
    "        print(\"Preparing data to run LDA...\")\n",
    "        corpus, id2word=process_data(self.DF, column_name)\n",
    "\n",
    "        print('Running LDA...')\n",
    "\n",
    "        start=time.time()\n",
    "        lda_model = gensim.models.LdaMulticore(corpus,num_topics=topic_num, id2word=id2word, passes=passes, workers=None,\n",
    "                                               chunksize=1000)\n",
    "        stop=time.time()\n",
    "\n",
    "        print(\"LDA complete\")\n",
    "        print(\"Total time: {}\".format(stop-start))\n",
    "\n",
    "        print(\"\\nStoring data in dataframe\")\n",
    "        \n",
    "        self.lda_model.append((topic_num,lda_model, session_id))\n",
    "        \n",
    "\n",
    "        for i,j in enumerate(self.DF.index):\n",
    "            index, score = sorted(lda_model[corpus[i]], key=lambda tup: -1*tup[1])[0]\n",
    "            self.DF.loc[j,str(topic_num)+'-topic']=index\n",
    "            self.DF.loc[j,str(topic_num)+'-topic-score']=score\n",
    "\n",
    "        print(\"Done\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def generate_LDA_plot(self,column_name,topic_num, repeats=1, pca=True):\n",
    "        \n",
    "        if len(self.lda_model)>0:\n",
    "            \n",
    "            for i in range(repeats):\n",
    "                column_name='Abstract_x'\n",
    "                title='LDA Plot for '+str(self.size)+' '+column_name+' for '+str(topic_num)+'topics-'+str(i)\n",
    "                sims=sim_calculator(self.DF, column_name)\n",
    "                var=tsne(sims,topic_num,self.DF,i)\n",
    "                sorted_dict=dictionarizer(self.DF,topic_num)\n",
    "                scatter(d,sorted_dict,topic_num,i,title,self.session_id,var)\n",
    "        \n",
    "        else:\n",
    "            print(\"No lda models found. Please run DF.run_LDA()\")\n",
    "                \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=NDF.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PII</th>\n",
       "      <th>Title_x</th>\n",
       "      <th>Abstract_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57770</th>\n",
       "      <td>S0925400511006022</td>\n",
       "      <td>Developing a new method of 4-(2-pyridylazo)-re...</td>\n",
       "      <td>An optical sensor responsive to gallium (III) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41030</th>\n",
       "      <td>S1566119911002886</td>\n",
       "      <td>Meta-linked CBP-derivatives as host materials ...</td>\n",
       "      <td>We present four derivatives of 4,4â²-bis(9-ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>S2214785320307732</td>\n",
       "      <td>Influence of defect related oxygen vacancies i...</td>\n",
       "      <td>In this work, SnO2 based precursor sol is subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93231</th>\n",
       "      <td>S1350448712000510</td>\n",
       "      <td>The role of opacifiers in the luminescence of ...</td>\n",
       "      <td>Thermoluminescence (TL) and radioluminescence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>S0167273815000843</td>\n",
       "      <td>Improving thermal stability and its effects on...</td>\n",
       "      <td>We investigated electrochemical substitution i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PII                                            Title_x  \\\n",
       "57770  S0925400511006022  Developing a new method of 4-(2-pyridylazo)-re...   \n",
       "41030  S1566119911002886  Meta-linked CBP-derivatives as host materials ...   \n",
       "2867   S2214785320307732  Influence of defect related oxygen vacancies i...   \n",
       "93231  S1350448712000510  The role of opacifiers in the luminescence of ...   \n",
       "14304  S0167273815000843  Improving thermal stability and its effects on...   \n",
       "\n",
       "                                              Abstract_x  \n",
       "57770  An optical sensor responsive to gallium (III) ...  \n",
       "41030  We present four derivatives of 4,4â²-bis(9-ca...  \n",
       "2867   In this work, SnO2 based precursor sol is subj...  \n",
       "93231  Thermoluminescence (TL) and radioluminescence ...  \n",
       "14304  We investigated electrochemical substitution i...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=Document(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NGwXJ0S0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.run_LDA('Abstract_x',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No lda models found. Please run DF.run_LDA()\n"
     ]
    }
   ],
   "source": [
    "D.generate_LDA_plot('Abstract_x',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
