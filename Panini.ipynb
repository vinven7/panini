{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python modules\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import threading\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "#Plotting Tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "#NLTK\n",
    "import nltk\n",
    "\n",
    "#Scikit learn models \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn. feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Import pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Chemdataextractor\n",
    "from chemdataextractor.doc import Document as Doc, Heading, Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list=[['AFM','atomic force microscop'],'electron densit',\\\n",
    "['SEM', 'scanning electron', 'BSE micrograph'], ['STM','Scanning tunneling'], ['band struct','band gap'],\\\n",
    "['XRD','X-ray diffrac','X ray diffrac'],'Strain','Raman spectr', ['TEM','Transmission electron microscop','HRTEM'],\\\n",
    "'Current-volt','Current volt','hysteresis','Thermodynamics', 'Network former', 'Network modifier', 'Cation', 'Anion',\\\n",
    "['DOS','Density of State'],'Phase diagram','Thermal conductivity', ['Scratch resistance','Scratch'],\\\n",
    "['Dielectric', 'Dielectric constant', 'Dielectric loss', 'breakdown', 'breakdown strength', 'BDS'],\\\n",
    "['TGA','Thermogravimetry'],\\\n",
    "['DSC','Differential scanning','Calorimetry', 'heat flow'], ['RI','Refractive ind'],\\\n",
    "'Cyclic volta',\\\n",
    "['FEM','finite element', 'FE'],['Magnetization curv', 'magnetization'], 'stress–strain curv',['plastic','ductil'],['tensi'],\\\n",
    "['compress'],\\\n",
    "'phonon',\n",
    "'microstruct',\\\n",
    "'mass spectr', 'current map', 'isotherms',\\\n",
    "['resist', '3D VG theory', '3D VGT formula'], 'conduct',\\\n",
    "['Polarizat','PV','polarizability'], ['Glass transition temperature', 'Glass transition','Tg'], ['Crystal', 'kinetics'],\\\n",
    "['phase separa','immiscibility'],['Liquidus temperature', 'Liquidus', 'solidus'],\\\n",
    "'Charge compensator',\\\n",
    "['BO','Bridging'], ['NBO', 'Non-bridging '], 'Hardness', ['Fracture toughness', 'KIC'], 'Density',\\\n",
    "'Modulus', 'Poisson’s ratio',\\\n",
    "['Thermal expansion', 'CTE', 'TEC'], ['Specific heat', 'heat capacity', 'adiabatic'], \\\n",
    "['Structure factor', 'Neutron scattering', 'FWHM','FSDP'], 'X-ray scattering', 'Indentation', 'radiation', 'bioactive',\\\n",
    "['distribution function'], ['transmission', 'transmi'],\\\n",
    "['absorp','absorb'],['reflect'],\\\n",
    "['MD','molecular dynamics','molecular simulation','BKS','CHIK'],['MC', 'Monte-Carlo', 'Monte carlo'],\\\n",
    "['Thermo lumines', 'Thermo-luminescence', 'TL'], 'Excitation',\\\n",
    "['optically stimulated luminescence', 'OSL','optical lumines'], ['Electron Diffrac','Selected Area Electron Diffraction', 'Thermo luminescence', 'SAED','SEAD','SAD'],\\\n",
    "[ 'EDX','Energy dispersive X-ray spectroscopy', 'X-ray spectroscopy', 'EDS', 'Xray spectroscopy', 'XPS'],\\\n",
    "['Energy diag', 'Energy level diag', 'Energy level transition', 'Energy level scheme', 'energy diagram'],\\\n",
    "['PLE', 'PL', 'Photolumines'],\\\n",
    "'stimulated emission', ['Gain coefficient', 'Gain measurement spectra', 'Optical gain',' Gain spectra', 'Gain cross-section'], 'lifetime',\\\n",
    "'leakage current density', ['lumines', 'Luminescence spectra', 'luminescence decay'],\\\n",
    "['MAS NMR', 'Magic Angle Spinning'] , ['emission', 'emission spectra'],['DTA', 'Differential thermal'],\\\n",
    "['free energy', 'Helmholtz', 'absorbed energy', 'gibbs energy'], ['CIE', 'chromaticity diag'], 'Weight loss',\\\n",
    "['strength', 'tensile strength', 'compressive strength', 'flexural strength', 'yield strength', 'ultimate strength', 'shear strength'],\\\n",
    " ['anneal','heat-treatment', 'sinter'], ['resonance', 'resonance freq’, ‘Electron paramagnetic resonance'], 'Impedance spect', \\\n",
    "'bonding scheme',['ionic conduc'], ['FTIR Spectr'],'IR emission',['Quantum efficiency','QE'],['iso-conversion plot'],\\\n",
    "['Tc','crystallization temperature','Tp'],'thermodynamic barrier',['UC emission', 'UC Luminescence', 'UC Spectra', 'UC Intensity'],'magnetic entropy', \\\n",
    "'energy trans', 'Cross relax', 'fracture', 'acoustic emiss', 'electric dipole',\\\n",
    "['NIR', 'NIR emission', 'NIR lumines','NIR fluores', 'Near Infra-red'], ['Relaxation time','relaxation'], ['IR transmi'],'quantum yield', ['Crack','Crack propagation','crack deflection'], \\\n",
    "'thermal sensit', 'CRET efficiency', 'spectral power distribution', 'HETCOR spect', ['UV-Vis absorp', 'Visible absorp', 'Visible spect', 'Visible emiss'], \\\n",
    "'fringe pattern', 'Tammann triangle',['lattice parameter', 'lattice constant', 'lattice'], 'current density',\\\n",
    "'FFT', 'Viscosity', \\\n",
    "'IR micrograph', 'Dilatometry', ['XEL spectr', 'X-ray excited luminescence spectr'], \\\n",
    "['Particle size distribution', 'Grain size distribution', 'PSD', 'GSD', 'Particle size', 'Grain size'], 'Optical absorp', ['activation energy','Kissinger', 'kinetics', 'Ozawa', 'JMA'], \\\n",
    "['CCT','correlated color temperature'], ['Eigen freq'], 'Abbe number', ['fluorescence','fluores','fluorescence intensity ratio', 'FIR'],\\\n",
    "['SERS Spect', 'Surface-enhanced Raman spect','SERS', 'Surface enhanced Raman spect'],'Molar Vol', 'IR fluores',\\\n",
    "['radio-lumines', 'RL Spect'], ['interface', 'interfac energ', 'permeation layer'],\\\n",
    "['VG transition line', 'VG'],\\\n",
    "['energy-storage density', 'storage'],\\\n",
    "['Qn', 'Q1', 'Q2', 'Q3', 'Q4'], ['MIR', 'MIR emission'],\\\n",
    "['angular', 'angular distribution'], \\\n",
    "'Z-scan',\\\n",
    "'Gruneisen', 'gamma ray',\\\n",
    "['Optical photograph', 'topology', 'Optical micrograph'],\\\n",
    "['dissolution','dissolve','flows','corros','leach','rotating disk method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEMENT_NAMES = ['hydrogen', 'helium', 'lithium', 'beryllium', 'boron', 'carbon', 'nitrogen', 'oxygen', 'fluorine',\n",
    "                     'neon', 'sodium', 'magnesium', 'aluminium', 'silicon', 'phosphorus', 'sulfur', 'chlorine', 'argon',\n",
    "                     'potassium', 'calcium', 'scandium', 'titanium', 'vanadium', 'chromium', 'manganese', 'iron',\n",
    "                     'cobalt', 'nickel', 'copper', 'zinc', 'gallium', 'germanium', 'arsenic', 'selenium', 'bromine',\n",
    "                     'krypton', 'rubidium', 'strontium', 'yttrium', 'zirconium', 'niobium', 'molybdenum', 'technetium',\n",
    "                     'ruthenium', 'rhodium', 'palladium', 'silver', 'cadmium', 'indium', 'tin', 'antimony', 'tellurium',\n",
    "                     'iodine', 'xenon', 'cesium', 'barium', 'lanthanum', 'cerium', 'praseodymium', 'neodymium',\n",
    "                     'promethium', 'samarium', 'europium', 'gadolinium', 'terbium', 'dysprosium', 'holmium', 'erbium',\n",
    "                     'thulium', 'ytterbium', 'lutetium', 'hafnium', 'tantalum', 'tungsten', 'rhenium', 'osmium',\n",
    "                     'iridium', 'platinum', 'gold', 'mercury', 'thallium', 'lead', 'bismuth', 'polonium', 'astatine',\n",
    "                     'radon', 'francium', 'radium', 'actinium', 'thorium', 'protactinium', 'uranium', 'neptunium',\n",
    "                     'plutonium', 'americium', 'curium', 'berkelium', 'californium', 'einsteinium', 'fermium',\n",
    "                     'mendelevium', 'nobelium', 'lawrencium', 'rutherfordium', 'dubnium', 'seaborgium', 'bohrium',\n",
    "                     'hassium', 'meitnerium', 'darmstadtium', 'roentgenium', 'copernicium', 'nihonium', 'flerovium',\n",
    "                     'moscovium', 'livermorium', 'tennessine', 'oganesson', 'ununennium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEMENTS = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K',\n",
    "                'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',\n",
    "                'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I',\n",
    "                'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb',\n",
    "                'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr',\n",
    "                'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf',\n",
    "                'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og', 'Uue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_labeller(DF,tag_list=tag_list):\n",
    "    \n",
    "    print(\"Commencing labeling...\")\n",
    "    label=0\n",
    "    \n",
    "    for t in tag_list:\n",
    "        \n",
    "        if type(t)==list:\n",
    "            \n",
    "            for tag in t:\n",
    "            \n",
    "                tag=tag.lower()\n",
    "                    \n",
    "                DF.loc[DF['Caption'].str.contains(tag,case=False,na=False,regex=True),'tag']=t[0]\n",
    "                DF.loc[DF['Caption'].str.contains(tag,case=False,na=False,regex=True),'label']=label\n",
    "        \n",
    "        if type(t)==str:\n",
    "            \n",
    "            tag=t.lower()\n",
    "             \n",
    "            DF.loc[DF['Caption'].str.contains(tag,case=False,na=False,regex=True),'tag']=t\n",
    "            DF.loc[DF['Caption'].str.contains(tag,case=False,na=False,regex=True),'label']=label\n",
    "        \n",
    "        label+=1\n",
    "    \n",
    "    DF.dropna(inplace=True)\n",
    "    \n",
    "    size_dict={}\n",
    "    \n",
    "    for tag in tag_list:\n",
    "        if type(tag)==list:\n",
    "            tag=tag[0]\n",
    "        val=len(DF[DF['tag']==tag])\n",
    "        size_dict[tag]=val\n",
    "    \n",
    "    for tag in tag_list:\n",
    "        if type(tag)==list:\n",
    "            tag=tag[0]\n",
    "        size_dict[tag]=np.around(size_dict[tag]*20/max(list(size_dict.values()))+7,2)\n",
    "    \n",
    "    sorted_dict={}\n",
    "    for w in sorted(size_dict, key=size_dict.get):\n",
    "        sorted_dict[w]=size_dict[w]\n",
    "        \n",
    "    print(\"Labelling complete...\")\n",
    "            \n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(DF, column_name):\n",
    "    data = DF[column_name].tolist()\n",
    "    data_words = list(sent_to_words(data))\n",
    "    \n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100) \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    data_words_nostops = [[word for word in simple_preprocess(str(doc)) if word not in STOPWORDS] for doc in data_words]\n",
    "    data_words_bigrams = [bigram_mod[doc] for doc in data_words_nostops]\n",
    "    \n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "    texts = data_words_bigrams\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "    return corpus, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_search(Query, pii, base):\n",
    "        \n",
    "        pii_path=os.path.join(base,Query,pii)\n",
    "        \n",
    "        TempDF=pd.DataFrame(columns=['Figname','No','Caption'])\n",
    "        \n",
    "        if os.path.isdir(pii_path):\n",
    "\n",
    "                cap_path=os.path.join(pii_path,pii+'-caption.txt')\n",
    "\n",
    "                if os.path.exists(cap_path):\n",
    "                    \n",
    "                        TempDF=pd.read_csv(cap_path,header=None, names=['Figname','No','Caption'])\n",
    "                        TempDF['Query']=Query\n",
    "                        TempDF['PII']=pii\n",
    "                \n",
    "        \n",
    "        return TempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascii4=re.compile('\\W+')\n",
    "number=re.compile('\\d+')\n",
    "extra_space=re.compile('\\s\\s+')\n",
    "\n",
    "def text_prepare(text):\n",
    "    temp=text.split(' ') \n",
    "    for word in STOPWORDS:\n",
    "        temp=[x for x in temp if x!=word]\n",
    "    text=' '.join(temp)\n",
    "    return text\n",
    "\n",
    "def preparer(DF):\n",
    "\n",
    "    \n",
    "    text=list(DF['Caption'])\n",
    "    \n",
    "    new_text=[]\n",
    "    for t in text:\n",
    "        if type(t)==str:\n",
    "            t=t.replace(' ','ABC')\n",
    "            t=ascii4.sub('',t)\n",
    "            t=number.sub('ABC',t)\n",
    "            t=t.replace('ABC',' ')\n",
    "            t=extra_space.sub(' ',t)\n",
    "            new_text.append(t)\n",
    "    \n",
    "    prepared = []\n",
    "    for line in new_text:\n",
    "        line = text_prepare(line.strip())\n",
    "        prepared.append(line)\n",
    "        \n",
    "    return prepared\n",
    "\n",
    "def vectorizer(prepared,DF,i):\n",
    "    \n",
    "    print('Featurizing\\n')\n",
    "    min_val=100\n",
    "    tfidf=TfidfVectorizer(min_df=min_val,max_df=0.9,ngram_range=(1,3))\n",
    "    \n",
    "    features=tfidf.fit_transform(prepared)\n",
    "    names=tfidf.get_feature_names()\n",
    "    \n",
    "    featDF=pd.DataFrame(features.todense(),columns=tfidf.get_feature_names())\n",
    "    \n",
    "    print('Cosine Matrix \\n')\n",
    "    X=featDF.values\n",
    "    distance_matrix = pairwise_distances(X, X, metric='cosine', n_jobs=-1)\n",
    "    \n",
    "    print('TSNE \\n')\n",
    "    state=random.randint(0,200)\n",
    "    time_start=time.time()\n",
    "    tsne=TSNE(n_components=2,metric=\"precomputed\",verbose=1,random_state=state,perplexity=40,n_iter=300)\n",
    "    tsne_results=tsne.fit_transform(distance_matrix)\n",
    "\n",
    "    print('t-SNE done! Time.elpased: {}'.format(time.time()-time_start))\n",
    "    \n",
    "    DF['State_'+str(i)]=state\n",
    "    DF['x-label-'+str(i)]=tsne_results[:,0]\n",
    "    DF['y-label-'+str(i)]=tsne_results[:,1]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def ccp_scatter(DF,sorted_dict,title,location,i=0):\n",
    "    \n",
    "    palette = np.array(sns.color_palette(\"hls\", len(sorted_dict)))\n",
    "    \n",
    "    f = plt.figure(figsize=(12, 12))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(DF['x-label-'+str(i)], DF['y-label-'+str(i)], lw=0, s=20,c=palette[DF['label'].astype(np.int)])\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    txts = []\n",
    "    for item in sorted_dict.keys():\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(DF[DF['tag']==item][['x-label-'+str(i),'y-label-'+str(i)]],axis=0)\n",
    "        if not math.isnan(xtext) and not math.isnan(ytext):\n",
    "            txt = ax.text(xtext, ytext, item, fontsize=sorted_dict[item])\n",
    "            txt.set_path_effects([\n",
    "                PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "                PathEffects.Normal()])\n",
    "            txts.append(txt)\n",
    "    \n",
    "    plt.savefig(os.path.join(location, title+'.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "             yield(simple_preprocess(str(sentence), deacc=True)) \n",
    "        \n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    text=\" \".join(text.split())\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in STOPWORDS and len(token) > 3:\n",
    "            result.append((token))\n",
    "    return result\n",
    "\n",
    "def sim_calculator(DF, column_name):\n",
    "\n",
    "    print(\"Number of {}: {}\".format(column_name,len(DF[column_name])))\n",
    "\n",
    "    #Preprocessing\n",
    "    print('\\nCreating Dictionary...')\n",
    "    processed_docs = DF[column_name].map(preprocess)\n",
    "\n",
    "    #Generating dictionary\n",
    "    dictionary = corpora.Dictionary(processed_docs)\n",
    "    dictionary.filter_extremes(no_below=100,no_above=0.9, keep_n=100000)\n",
    "    print('Dictionary created')\n",
    "    print(\"Size of vocabularly: \",len(dictionary))\n",
    "\n",
    "    #Bag of words\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "    #Tfid vectorization\n",
    "    print('\\nRunning TFIDF vectorization...')\n",
    "    model2 = TfidfModel(bow_corpus) \n",
    "    abs_tfidf=model2[bow_corpus]\n",
    "    print('TFIDF complete')\n",
    "\n",
    "    #Calculating similarties\n",
    "    print('\\nCalculating Similarity Matrix...')\n",
    "    index = similarities.MatrixSimilarity(abs_tfidf)\n",
    "    sims = index[abs_tfidf]\n",
    "    print(\"size of similarity matrix: \", sims.shape)\n",
    "\n",
    "    return sims\n",
    "\n",
    "def tsne(sims,title,DF,i):\n",
    "\n",
    "    #run PCA\n",
    "    print(\"\\nBeginning clustering...\")\n",
    "    N=100\n",
    "    pca = PCA(n_components=N)\n",
    "    pca_result = pca.fit_transform(sims)\n",
    "    var=np.sum(pca.explained_variance_ratio_)\n",
    "    print(\"\\nPCA calculated\")\n",
    "    print('Cumulative explained variation for {} principal components: {}'.format(N,var))\n",
    "\n",
    "    #Running TSNE\n",
    "    print(\"Creating TSNE labels...\")\n",
    "    tsne=TSNE(n_components=2,verbose=1,perplexity=40,n_iter=300)\n",
    "    tsne_results=tsne.fit_transform(pca_result)\n",
    "    print(\"TSNE complete\")\n",
    "    DF['x-label-'+str(i)]=tsne_results[:,0]\n",
    "    DF['y-label-'+str(i)]=tsne_results[:,1]\n",
    "\n",
    "    return str(np.round(var*100,2))\n",
    "\n",
    "def dictionarizer(DF,topic_num):\n",
    "    \n",
    "    topic_num=str(topic_num)\n",
    "    size_dict={}\n",
    "    tag_list=list(set(DF[topic_num+'-topic']))\n",
    "\n",
    "    for tag in tag_list:\n",
    "        val=len(DF[DF[topic_num+'-topic']==tag])\n",
    "        size_dict[str(tag)]=val\n",
    "\n",
    "    for tag in tag_list:\n",
    "        size_dict[str(tag)]=np.around(size_dict[str(tag)]*20/max(list(size_dict.values()))+7,2)\n",
    "\n",
    "    sorted_dict={}\n",
    "    for w in sorted(size_dict, key=size_dict.get):\n",
    "        sorted_dict[w]=size_dict[w]\n",
    "\n",
    "    return sorted_dict\n",
    "\n",
    "def lda_scatter(DF,sorted_dict,topic_num,i,title,location,var='62.3'):\n",
    "    \n",
    "    sample_size=len(DF)\n",
    "    \n",
    "    topic_num=str(topic_num)\n",
    "    print(\"\\nCreating LDA plot...\")\n",
    "\n",
    "    if len(DF)>=50000:\n",
    "        s=10\n",
    "    else:\n",
    "        s=40\n",
    "\n",
    "    palette = np.array(sns.color_palette(\"hls\", len(sorted_dict)+5))\n",
    "\n",
    "    f = plt.figure(figsize=(12, 12))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(DF['x-label-'+str(i)], DF['y-label-'+str(i)], s,lw=0,c=palette[DF[topic_num+'-topic'].astype(np.int)])\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    txts = []\n",
    "    for item in sorted_dict.keys():\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(DF[DF[topic_num+'-topic']==float(item)][['x-label-'+str(i),'y-label-'+str(i)]],axis=0)\n",
    "        if not math.isnan(xtext) and not math.isnan(ytext):\n",
    "            txt = ax.text(xtext, ytext, item, fontsize=sorted_dict[item])\n",
    "            txt.set_path_effects([\n",
    "                PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "                PathEffects.Normal()])\n",
    "            txts.append(txt)\n",
    "\n",
    "    PCA_text='PCA: 100 \\nTotal Variance: '+var\n",
    "\n",
    "    plt.title('Cluster plot of '+str(sample_size)+' Abstracts with '+topic_num+' topics')\n",
    "    plt.annotate(PCA_text, xy=(0,0), xytext=(12, 80), va='top',xycoords='axes fraction', textcoords='offset points')\n",
    "    plt.savefig(os.path.join(location, 'LDA plot.png'))\n",
    "    print(\"\\nLDA plot saved as {} at {}\".format(title+'.png',location))\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(DF,X):\n",
    "    if DF[X]:\n",
    "        return 'red'\n",
    "    else:\n",
    "        return'grey'\n",
    "    \n",
    "def size(DF,X):\n",
    "    if DF[X]:\n",
    "        return 20\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chem_finder(DF,column_name):\n",
    "    \n",
    "    doc=Doc(DF[column_name])\n",
    "    records=doc.records.serialize()\n",
    "    \n",
    "    try:\n",
    "        chem_rec='_'\n",
    "        for rec in records:\n",
    "            \n",
    "            if 'names' in str(rec.keys()):\n",
    "                chem_rec+=', '+rec['names'][0]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return chem_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plotter(dictionary, number, xlabel, ylabel, title, location, xticks= False, save=True):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.bar(list(dictionary.keys())[:number], list(dictionary.values())[:number])\n",
    "    plt.xlabel(xlabel)\n",
    "    if xticks:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if save: \n",
    "        plt.savefig(location)\n",
    "    plt.show\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \n",
    "    def __init__(self,address):\n",
    "        \n",
    "        self.session_id=self.randomString()\n",
    "        \n",
    "        if type(address)==str:\n",
    "            self.DF=pd.read_csv(address)\n",
    "        elif isinstance(address, pd.DataFrame):\n",
    "            self.DF=address.copy()\n",
    "        \n",
    "        self.size=len(self.DF)\n",
    "        \n",
    "        self.lda_model=[]\n",
    "        \n",
    "        self.caption_DF=pd.DataFrame()\n",
    "        self.lda_topic_DF=pd.DataFrame()\n",
    "        \n",
    "        self.caption_labels_dictionary={}\n",
    "        self.chemicals_dictionary={}\n",
    "        self.tag_dict={}\n",
    "        self.lda_dict={}\n",
    "        \n",
    "        self.location=os.path.join(os.getcwd(),self.session_id)\n",
    "        os.mkdir(self.location)\n",
    "        \n",
    "    def randomString(self,stringLength=8):\n",
    "        lettersAndDigits = string.ascii_letters + string.digits\n",
    "        return ''.join(random.choice(lettersAndDigits) for i in range(stringLength))\n",
    "    \n",
    "    def generate_Captions(self,PII='PII',Query='Query',base=os.getcwd()):\n",
    "        Cap_list=[]\n",
    "        for row in self.DF.index:\n",
    "            pii=self.DF.loc[row,PII]\n",
    "            Q=self.DF.loc[row,Query]\n",
    "            TempDF=folder_search(Q,pii,base)\n",
    "            Cap_list.append(TempDF)\n",
    "            \n",
    "        self.caption_DF=pd.concat(Cap_list)\n",
    "        \n",
    "        print(\"Caption generation complete. \\nNo of Captions found : {}\".format(len(self.caption_DF)))\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def plot_caption_cluster(self, iterations=1):\n",
    "        prepared=preparer(self.caption_DF)\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            TDF=vectorizer(prepared,self.caption_DF,i) \n",
    "            title='Caption cluster plot of '+str(len(self.caption_DF))+'Captions-'+str(i)\n",
    "            ccp_scatter(self.caption_DF,self.caption_labels_dictionary,title,self.location, i)\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    def label_Captions(self,tag_list=tag_list):\n",
    "        \n",
    "        if len(self.caption_DF)>0:\n",
    "            self.caption_labels_dictionary=caption_labeller(self.caption_DF,tag_list=tag_list)\n",
    "        else:\n",
    "            print(\"No captions found. Run DF.generate_Captions()\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def run_LDA(self,column_name, topic_num, passes=10, save= True):\n",
    "        \n",
    "        print(\"Preparing data to run LDA...\")\n",
    "        corpus, id2word=process_data(self.DF, column_name)\n",
    "\n",
    "        print('Running LDA...')\n",
    "\n",
    "        start=time.time()\n",
    "        lda_model = gensim.models.LdaMulticore(corpus,num_topics=topic_num, id2word=id2word, passes=passes, workers=None,\n",
    "                                               chunksize=1000)\n",
    "        stop=time.time()\n",
    "\n",
    "        print(\"LDA complete\")\n",
    "        print(\"Total time: {}\".format(stop-start))\n",
    "\n",
    "        print(\"\\nStoring data in dataframe\")\n",
    "        \n",
    "        self.lda_model.append((topic_num,lda_model, self.session_id))\n",
    "        \n",
    "        if save:\n",
    "            F=open(os.path.join(self.location,'Lda_model.pickle'),'wb')\n",
    "            pickle.dump(self.lda_model,F)\n",
    "            F.close()\n",
    "\n",
    "        for i,j in enumerate(self.DF.index):\n",
    "            index, score = sorted(lda_model[corpus[i]], key=lambda tup: -1*tup[1])[0]\n",
    "            self.DF.loc[j,str(topic_num)+'-topic']=index\n",
    "            self.DF.loc[j,str(topic_num)+'-topic-score']=score\n",
    "\n",
    "        print(\"Done\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def generate_LDA_plot(self,column_name,topic_num, repeats=1, pca=True):\n",
    "        \n",
    "        if len(self.lda_model)>0:\n",
    "            \n",
    "            for i in range(repeats):\n",
    "                column_name='Abstract_x'\n",
    "                title='LDA Plot for '+str(self.size)+' '+column_name+' for '+str(topic_num)+'topics-'+str(i)\n",
    "                sims=sim_calculator(self.DF, column_name)\n",
    "                var=tsne(sims,topic_num,self.DF,i)\n",
    "                sorted_dict=dictionarizer(self.DF,topic_num)\n",
    "                lda_scatter(self.DF,sorted_dict,topic_num,i,title,self.location,var)\n",
    "        \n",
    "        else:\n",
    "            print(\"No lda models found. Please run DF.run_LDA()\")\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def generate_LDA_topic_df(self, n=10, save=False):\n",
    "        topic_list=[]\n",
    "        for topic in self.lda_model[0][1].print_topics(-1):\n",
    "            titles=topic[1].split(\"\\\"\")\n",
    "            A=2*n #len(titles)\n",
    "            word_list=[]\n",
    "            for i in range(1,A,2):\n",
    "                word_list.append(titles[i])\n",
    "            topic_list.append(word_list)  \n",
    "            \n",
    "        X=np.arange(len(self.lda_model[0][1].print_topics(-1)))\n",
    "        DF=pd.DataFrame([X,topic_list]).T\n",
    "        DF.columns=['Topic No','Keywords']\n",
    "        DF.set_index('Topic No', inplace=True)\n",
    "        \n",
    "        self.lda_topic_DF=DF\n",
    "        print(self.lda_topic_DF)\n",
    "        \n",
    "        if save:\n",
    "            self.lda_topic_DF.to_csv(os.path.join(self.location,'lda-topics-df.csv'))\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def extract_chemicals(self, column_name):\n",
    "        \n",
    "        print(\"Starting Chemical Extraction\")\n",
    "        self.DF['Chemicals']=None\n",
    "        self.DF['Chemicals']=self.DF.apply(chem_finder, args=(column_name,),axis=1)\n",
    "        print(\"Chemical Extraction complete\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def create_chemical_dictionary(self):\n",
    "        print(\"\\nGenerating Chemical Dictionary\")\n",
    "        chem_dict={}\n",
    "        \n",
    "        for no,index  in enumerate(self.DF.index):\n",
    "            \n",
    "            chemicals=self.DF.loc[index,'Chemicals']\n",
    "            \n",
    "            if type(chemicals)==str:\n",
    "                \n",
    "                tokens=chemicals.split(',')[1:]\n",
    "                for tok in tokens:\n",
    "                    tok=tok.strip()\n",
    "                    if tok in chem_dict.keys():\n",
    "                        chem_dict[tok]+=1\n",
    "                    else:\n",
    "                        chem_dict[tok]=1\n",
    "                        \n",
    "        self.chemicals_dictionary = dict(sorted(chem_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "                        \n",
    "        print(\"Chemical Dictionary generated\")\n",
    "        \n",
    "        F=open('chemical_dictionary.pickle','rb')\n",
    "        Chem_dict=pickle.load(F)\n",
    "        F.close()\n",
    "        \n",
    "        print(\"Creating Chemical columns\")\n",
    "        \n",
    "        for el in ELEMENTS:\n",
    "            self.DF[el]=0\n",
    "\n",
    "        for no, index in enumerate(self.DF.index):\n",
    "            \n",
    "            chemicals=self.DF.loc[index,'Chemicals']\n",
    "            \n",
    "            if type(chemicals)==str:\n",
    "                \n",
    "                Chem_list=[i.strip() for i in chemicals.split(',')]\n",
    "                \n",
    "                for c in Chem_list:\n",
    "                    if c in Chem_dict.keys():\n",
    "                        for j in Chem_dict[c].keys():\n",
    "                            self.DF.loc[index,j]=1\n",
    "        \n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def generate_elemental_maps(self):\n",
    "        j=0    \n",
    "    \n",
    "        for i in ELEMENTS:\n",
    "            self.DF['color']=self.DF.apply(color,args=[i,],axis=1)\n",
    "            self.DF['size']=self.DF.apply(size,args=[i,],axis=1)\n",
    "            \n",
    "            f = plt.figure(figsize=(12, 12))\n",
    "            ax = plt.subplot(aspect='equal')\n",
    "            \n",
    "            sc = ax.scatter(self.DF['x-label-'+str(j)],self.DF['y-label-'+str(j)], s=self.DF['size'],lw=0,c=self.DF['color'])\n",
    "            \n",
    "            ax.title.set_text(i)\n",
    "            ax.axis('off')\n",
    "            ax.axis('tight')\n",
    "            plt.savefig(os.path.join(self.location,i+'_15.png'))\n",
    "            plt.show()\n",
    "            plt.close()    \n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def generate_records(self):\n",
    "        lda_dict={}\n",
    "        topic_set=set(self.DF['15-topic'])\n",
    "        for topic in topic_set:\n",
    "            lda_dict[topic]=len(self.DF[self.DF['15-topic']==topic])\n",
    "        lda_dict=dict(sorted(lda_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "        self.lda_dict=lda_dict\n",
    "        if len(self.lda_dict)>0:\n",
    "            bar_plotter(self.lda_dict, 15, 'Topic No', 'Count', 'LDA Topic Distribution', os.path.join(self.location, 'lda_topic_dist.jpg'), save=True)\n",
    "            \n",
    "        tag_dict={}\n",
    "        tag_set=set(self.caption_DF['tag'])\n",
    "        for tag in tag_set:\n",
    "            tag_dict[tag]=len(self.caption_DF[self.caption_DF['tag']==tag])\n",
    "        tag_dict=dict(sorted(tag_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "        self.tag_dict=tag_dict\n",
    "        if len(self.tag_dict)>0:\n",
    "            bar_plotter(self.tag_dict, 25, 'Tags', 'Count', 'Tags Distribution', os.path.join(self.location, 'tags_dist.jpg'), xticks=True, save=True)           \n",
    "        \n",
    "        if len(self.chemicals_dictionary)>0:\n",
    "            bar_plotter(self.chemicals_dictionary, 25, 'Chemicals', 'Count', 'Chemical Distribution', os.path.join(self.location, 'chem_dist.jpg'), xticks=True, save=True)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save(self):\n",
    "        self.DF.to_csv(os.path.join(self.location, 'DataRecords.csv'))\n",
    "        self.caption_DF.to_csv(os.path.join(self.location, 'Captions.csv'))\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
